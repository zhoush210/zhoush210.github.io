---
layout: post
title:  "第6讲 非线形优化"
subtitle: "高翔《SLAM十四讲》"
date:   2023-1-10 17:17:00 +0800
author:     "ZhouSh"
header-img: "img/in_post/SLAM14/head.png"
header-mask: 0.4
tags:
    - SLAM十四讲
---
# 第6讲　非线形优化
<!-- $$\begin{equation}
x_k=f(x_{k-1},u_k)+w_k
\end{equation}$$

$\begin{eqnarray}
x_k=f(x_{k-1},u_k)+w_k
\end{eqnarray}$ -->

## 6.1 状态估计问题

经典SLAM模型由状态方程和运动方程构成：
$
x_k=f(x_{k-1},u_k)+w_k
\tag{1}
$

$
z_{k,j}=h(y_j,x_k)+v_{k,j}
\tag{2}
$

在非线性优化中，把所有待估计的变量放在一个“状态变量”中：$x=\{x_1,\cdots,x_N,y_1,\cdots,y_M\}$

为了估计状态变量的条件分布，利用**贝叶斯法则**，有：

$
P(x\|z)=\frac{P(z\|x)P(x)}{P(z)}\propto P(z\|x)P(x)
\tag{3}
$

贝叶斯法则的左侧 $P(x\|z)$ 通常被称为**后验概率**，右侧 $P(z\|x)$ 称为似然，$P(x)$ 称为先验。直接求后验分布是困难的，但是求一个状态最优估计，使得在该状态下后验概率最大化（Maximize a Posterior，MAP），则是可行的：

$
x^*_{MAP}=arg\ max\ P(x\|z)=arg\ max\ P(z\|x)P(x)
\tag{4}
$

贝叶斯法则的分母与代估计的状态x无关，因而可以忽略。贝叶斯法则告诉我们，求解最大后验概率相当于最大化似然和先验的乘积。当不知道机器人位姿大概在哪时，就没有了先验。那么，可以求解x的**最大似然估计**（Maximize Likelihood Eistimation，MLE）：

$
x^*_{MLE}=arg\ max\ P(z\|x)
\tag{5}
$

直观讲，**似然**是指“在现在的位姿下，可能产生怎样的观测数据”。**最大似然估计**可以理解成“在什么样的状态下，最可能产生现在观测到的数据”。

高维高斯分布的概率密度函数为：

$
P(x)=\frac 1{\sqrt{(2\pi)^Ndet(\Sigma)}}exp(-\frac12(x-\mu^T\Sigma^{-1}(x-\mu)))
\tag{6}
$

一般用**最小化负对数**来求一个高斯分布的最大似然，对其取负对数，得：

$
-ln(P(x))=\frac12ln((2\pi)^Ndet(\Sigma))+\frac12(x-\mu)^T\Sigma^{-1}(x-\mu)
\tag{7}
$

第一项与x无关，舍去，只要最小化右侧的二次型项，就得到对状态的最大似然估计。

代入SLAM的观测模型，得：

$
x^*=arg\ min((z_{k,j}-h(x_k,y_j))^TQ^{-1}_{k,j}(z_{k,j}-h(x_k,y_j)))
\tag{8}
$

代入SLAM的观测模型，得：

$
x^*=arg\ min((x_k-f(x_{k-1},u_k))^TR^{-1}_k(x_k-f(x_{k-1},u_k)))
\tag{9}
$

令误差为

$
e_{v,k}=x_k-f(x_{k-1},u_k)
\tag{10}
$

$
e_{y,j,k}=z_{k,j}-h(x_k,y_j)
\tag{11}
$

那么整个SLAM的误差平方和为

$
J(x)=\Sigma_ke^T_{v,k}R^{-1}_ke_{v,k}+\Sigma_k\Sigma_je^T_{y,k,j}Q^{-1}_{k,j}e_{y,k,j}
\tag{12}
$

## 6.2 非线性最小二乘

对于不方便直接求解的最小二乘问题，可以用**迭代**的方式，步骤如下：

1. 给定初始值$x_0$
2. 对于第k次迭代，寻找一个增量$\Delta x_k$，使得$\|\|f(x_k+\Delta x_k)\|\|^2_2$达到极小值
3. 若$\Delta x_k$足够小，则停止
4. 否则，令$x_{k+1}=x_k+\Delta x_k$，返回第二步

确定增量$\Delta x_k$常用的方式有2种：**高斯牛顿法**和**列文伯格-马夸尔特法**

### 6.2.1 一阶梯度法(最速下降法) 和 二阶梯度法(牛顿法)

求解增量最直观的方式是将目标函数在x附近泰勒展开：

$
\|\|f(x+\Delta x)^2_2\approx\|\|f(x)\|\|^2_2+J(x)\Delta x+\frac 12\Delta x^TH\Delta x
\tag{13}
$
> 其中$J$是$\|\|f(x)\|\|^2$关于x的导数（雅可比矩阵），$H$是二阶导数（海塞矩阵Hessian）

我们可以选择保留泰勒展开的一阶或二阶项，对应的求解方法则为一阶梯度法或二阶梯度法。

若保留一阶梯度，则增量的解为：

## 参考
[CSDN：SLAM最小二乘的引出](https://blog.csdn.net/weixin_43205582/article/details/102929510)