---
layout: post
title:  "回环检测"
subtitle:   "Bag of Word"
date:   2022-11-24 09:05:00 +0800
author:     "ZhouSh"
header-img: "img/in_post/loop-closing/head.png"
header-mask: 0.2
tags:
    - SLAM论文
---
我们可以把仅有前端和局部后端的系统称为**VO**，而把带有回环检测和全局后端的系统称为**SLAM**

### 朴素的回环检测：
- 对任意两幅图像都做一遍特征匹配
- 随机抽取历史数据并进行回环检测

### 预计哪出可能出现回环：
1. 基于里程计的几何关系（Odometry based）（存在倒为因果的假设，累积误差较大时不适用）
2. 基于外观（Appearance based）（词袋模型BoW）

### 准确率和召回率
<img src="/img/in_post/loop-closing/1.png" width="70%">

- 假阳性又称**感知偏差**，假阴性又称**感知变异**
- 准确率：Precision=TP/(TP+FP)，描述算法提取的所有回环中确实是真实回环的概率
- 召回率：Recall=TP/(TP+FN)，描述在所有真实回环中被正确检测出来的概率
- 在SLAM中，我们对准确率的要求更高，对召回率则相对宽容（宁可放过一千，绝不错杀一个！hhh）

### 词袋模型BoW
<img src="/img/in_post/loop-closing/3.png" width="40%">
- 用 “图像上有哪些特征” 来描述一幅图像，假设字典为[眼，鼻，口，手]，则一幅仅包含一张人脸的图像可描述为[2，1，1，0]或[1，1，1，0]（不考虑数量），与特征的空间位置和排列顺序无关
- 考虑到字典通用性，通常会使用一个较大规模的字典，以保证当前使用环境中的图像特征都在其中
- 可用k叉树来表达字典（有点像生物中的界门纲目科属种）

### K-means
字典的生成问题类似一个聚类问题，可以用K-means解决，步骤如下：
1. 随机选取k个中心点
2. 对每个样本，计算他们与每个中心点之间的距离，取最小的作为它的归类
3. 重新计算每个类的中心点
4. 如果每个中心点的变化很小，则算法收敛，退出；否则返回第2步重复

### 相似度计算
我们希望对单词的区分性或重要性加以评估，给他们不同的权值以起到更好的效果。在文本检索中常用的一种做法是TF-IDF（Term Frequency-Inverse Document Frequency）。TF的思想是某单词在一幅图像中经常出现，它的区分度就高；IDF的思想是某单词在一幅图像中出现的频率越低，它的区分度越高。
<img src="/img/in_post/loop-closing/2.png" width="80%">

### 相似性评分的处理
仅仅利用相似性不一定合适，比如办公室往往有很多同款桌椅。所以我们会先取一个先验相似度，表示某时刻关键帧图像与上以时刻关键帧的相似性，然后其他的分支都参照这个值归一化。比如说，如果当前帧与之前某关键帧的相似度超过当前帧与上一关键帧相似度的3倍，就认为可能存在回环。

### 检测之后的验证
词袋的回环检测算法完全依赖于外观而没有利用任何的几何信息，这导致外观相似的图像容易被当成回环。并且，由于词袋不在乎单词顺序，只在意单词有无的表达方式，更容易引发感知偏差。所以，在回环检测之后，我们通常还会有一个验证步骤
- **时间一致性检测**：设立回环的缓存机制，认为单次检测到的回环并不足以构成良好的约束，而在一段时间中一直检测到的回环，才认为是正确的回环。
- **空间一致性检测**：对回环检测到的两个帧进行特征匹配，估计相机的运动。然后，再把运动放到之前的Pose Graph中，检查与之前的估计是否有很大的出入。

## 参考
- 《slam十四讲》