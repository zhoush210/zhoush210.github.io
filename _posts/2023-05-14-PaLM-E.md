---
layout: post
title:  "PaLM-E"
subtitle: "PaLM-E: An Embodied Multimodal Language Model"
date:   2023-05-14 16:19:00 +0800
author:     "ZhouSh"
header-img: "img/in_post/PaLM-E/head.png"
header-mask: 0.5
tags:
    - 论文笔记
---

> 聊天时 yiyi推荐的论文。没接触过这块，所以不注重细节，理个大概，弄清楚来龙去脉即可

- 论文：[PaLM-E: An Embodied Multimodal Language Model](https://arxiv.org/pdf/2303.03378.pdf)

- 官网：[palm-e.github.io](https://palm-e.github.io/)

这篇论文的名字是 "**具身多模态语言模型**"（Embodied Multimodal Language Model）$^{[1]}$：

1. **具身（Embodied）**：表示该模型接入了机器人，具有了身体。
2. **多模态（Multimodal）**：表示该模型的**输入**是多模态的，包括文本（text）、图像（visual）、连续状态（continuous state estimation）。
3. **语言（Language）**：表示该模型的输出只有文本。但是输出文本已经不再限制于自然语言，已经被玩出花来了。因为代码本身也是文本，所以模型的输出可以是一段**代码**，代码执行完之后可以是一段机器人可识别的指令；也可以模型直接输出机器人可识别的**指令**；这样模型的**输出结果就可以操作机器人**。

最近OpenAI发布的Chat-GPT也是输入为多模态，输出为纯文本。
## Abstract
1. 提出了一种具身语言模型，可以直接将真实世界的连续传感器模态输入语言模型中，从而建立**单词和感知**之间的联系。
2. 模型的输入是多模态句子，包括视觉、连续状态估计、文本输入编码。
3. 用预训练的**大语言模型**进行**端到端**的训练，我们可以针对多种具身任务进行训练（包括机器人操作规划、视觉问答、字幕生成）。

> “端到端”（End-to-End）指系统将输入数据直接作为输入，通过一系列处理层（例如神经网络）进行处理，并直接输出最终结果，而不需要手动对输入数据进行特征提取或手动设计中间处理步骤。

## 1.Introduction
1. 大语言模型（LLM）在各个领域表现出强大的**推理能力**，包括对话、分步推理、数学问题解决、代码编写。然而现实世界中此类推理模型的**局限性**在于一个**grounding**问题：如何将**单词和感知**联系起来。
2. 本文提出了具身语言模型，它直接接收传感器模态的连续输入，使语言模型能够为现实世界中的顺序决策做出更为基础的推断。

> 在自然语言处理和人工智能领域，"**grounding**"（也称为"semantic grounding"）是指将语言与实际世界的概念联系起来，使语言具有实际意义和实际执行的能力。简而言之，grounding是将抽象的语言符号与具体的物理世界相对应的过程。

## 2.Related Work

1. **通用视觉语言模型**（General vision-language modeling）：VLM能够同时理解图像和文本，并且可以应用于诸如视觉问答、字幕、光学字符识别、物体检测等任务。整合图像的方法各不相同。
2. **动作输出模型**（Actions-output models）：之前的工作侧重于将具体环境中的视觉和语言输入与直接行动预测目标相结合。
3. **具身任务规划中的LLM**（LLMs in embodied task planning）：大多数工作聚焦于自然语言目标，很少将自然语言作为规划决策（planning）的表达。LLM包含大量有关现实世界的知识，但没有grounding的话，生成的决策将无法执行。

## 3.PaLM-E: An Embodied Multimodal Language Model

1. PaLM-E的主要架构是将连续的具身观测（如图像、状态估计、传感器模态）注入到预训练模型的**语言嵌入空间**中。输入的连续观测像输入的文本一样，**编码**为与文本在嵌入空间具有相同维度的向量序列（token），然后输入到模型中。
2. PaLM-E是一个仅具有解码器的语言模型，可以在给定前缀或提示的条件下，自动逐步生成文本。
3. PaLM-E = google发布的预训练模型PaLM + Embodied。

> **语言嵌入空间**是指在语言模型中，单词、短语或句子以数字形式的概念表示。在这个背景下，预训练语言模型的语言嵌入空间指的是将语言信息编码和处理的潜在空间。

### 3.1.Decoder-only LLMs

仅解码大语言模型就是给定前面序列的token，预测联合概率最大的下一个token。如式（1），其中$w_{1:L}$为输入文本转化成的token，$p_{LM}$是一个大型transform网络。

$
p(w_{1:L})=\prod^L_{l=1}p_{LM}(w_l|w_{1:l-1})
\tag{1}
$

### 3.2.Prefix-decoder-only LLMs

由于LLM是**自回归**的，预训练的模型可以以前缀$w_{1:n}$为条件，而无需更改架构。在式（2）中，位置1到n是prefix prompt，从位置n+1往后才是输入的文本数据。在训练时，prefix prompt部分不参与计算loss。

$
p(w_{n+1:L}|w_{1:n})=\prod^L_{l=n+1}p_{LM}(w_l|w_{1:l-1})
\tag{2}
$

> 在语言模型中，"**自回归**"（auto-regressive）指的是模型通过预测先前生成的token来逐个生成输出。换句话说，模型按顺序生成输出，每个token都依赖于之前生成的token。

### 3.3.Token embedding space

token $w_i$是固定词汇表W的一个元素，该词汇表是一个离散的有限集合，对应于自然语言中的子集。$\mathcal{X} \in R^k$表示整个嵌入空间。$\gamma$表示一个大小为$k\times \|W\|$的大型嵌入矩阵（$\|W\|=256000$），并进行端到端的训练。$x_i$表示某个token的嵌入向量。词嵌入的过程可以表示为（3）。

$
x_i = \gamma(w_i)
\tag{3}
$

### 3.4.Multi-modal sentences: injection of continuous observations

传感器观测到的连续状态可以映射到语言嵌入空间$\mathcal{X}$。为此需要训练一个编码器（详见第4节）$\phi=\mathcal{O}\rightarrow\mathcal{X}^q$ 将连续观测$\mathcal{O}$ 映射为$\mathcal{X}$中的q维token向量。然后将这些向量与普通嵌入文本token交错，以形成LLM的前缀。这意味着前缀中的每个向量$x_i$由单词标记嵌入器$\gamma$或编码器$\phi_i$构成（如下式）。注意，单个观测$\mathcal{O}_j$ 通常被编码为多个嵌入向量。
<img src="/img/in_post/PaLM-E/1.png" width="60%">

## 4.Input & Scene Representations for Different Sensor Modalities

# 参考
- [[1] PaLM-E: 具身多模态语言模型](https://zhuanlan.zhihu.com/p/615879292)
- [论文翻译](https://zhuanlan.zhihu.com/p/613316732)