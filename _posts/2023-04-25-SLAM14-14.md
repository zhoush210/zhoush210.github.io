---
layout: post
title:  "第14讲 SLAM:现在和未来"
subtitle: "高翔《SLAM十四讲》"
date:   2023-4-25 10:28:00 +0800
author:     "ZhouSh"
header-img: "img/in_post/SLAM14/head.png"
header-mask: 0.4
tags:
    - SLAM十四讲
---
# 第14讲 SLAM：现在与未来

## 14.1　当前的开源方案

往往论文中介绍理论只占20%的内容，其他80%都写在代码中，是论文里没有提到的。

方案名称|传感器形式|地址
MonoSLAM|单目|<https://github.com/hanmekim/SceneLib2>
PTAM|单目|<https://www.robots.ox.ac.uk/~gk/PTAM/>
ORB-SLAM|单目为主|<https://webdiis.unizar.es/~raulmur/orbslam/>
LSD-SLAM|单目为主|<https://cvg.cit.tum.de/research/vslam/lsdslam>
SVO|单目|<https://github.com/uzh-rpg/rpg_svo>
DTAM|RGB-D|<https://github.com/anuranbaka/OpenDTAM>
DVO|RGB-D|<https://github.com/tum-vision/dvo_slam>
DSO|单目|<https://github.com/JakobEngel/dso>
RTAB-MAP|双目/RGB-D|<https://github.com/introlab/rtabmap>
RGBD-SLAM-V2|RGB-D|<https://github.com/felixendres/rgbdslam_v2>
Elastic Fusion|RGB-D|<https://github.com/mp3guy/ElasticFusion>
Hector SLAM|激光|<https://wiki.ros.org/hector_slam>
GMapping|激光|<https://wiki.ros.org/gmapping>
OKVIS|多目+IMU|<https://github.com/ethz-asl/okvis>
ROVIO|单目+IMU|<https://github.com/ethz-asl/rovio>

### 14.1.1　MonoSLAM

Davison教授是视觉SLAM研究领域的先驱，他在2007年提出的MonoSLAM是第一个实时的单目视觉SLAM系统，被认为是许多工作的发源地。MonoSLAM以**扩展卡尔曼滤波**为后端，追踪前端非常稀疏的特征点。由于EKF在早期SLAM中占据着明显主导地位，所以MonoSLAM亦是建立在EKF的基础之上，以相机的当前状态和所有路标点为状态量，更新其均值和协方差。

### 14.1.2　PTAM

2007年，Klein等人提出了PTAM（Parallel Tracking and Mapping），这也是视觉SLAM发展过程中的重要事件。PTAM的重要意义在于以下两点：

1.PTAM提出并实现了跟踪与建图过程的**并行化**。这是视觉SLAM中首次区分出**前后端**的概念。

2.PTAM是第一个使用**非线性优化**，而不是使用传统的滤波器作为后端的方案。它引入了**关键帧机制**：我们不必精细地处理每一幅图像，而是把几个关键图像串起来，然后优化其轨迹和地图。

### 14.1.3　ORB-SLAM

ORB-SLAM提出于2015年，代表着主流的特征点SLAM的一个高峰。相比于之前的工作，ORB-SLAM具有以下几条明显的优势：

1.支持单目、双目、RGB-D三种模式。

2.整个系统围绕**ORB特征**进行计算，包括视觉里程计与回环检测的ORB字典。

3.ORB的**回环检测**是它的亮点。ORB-SLAM在运行之前必须加载一个很大的ORB字典文件。

4.ORB-SLAM创新式地使用了**三个线程**完成SLAM：实时跟踪特征点的**Tracking线程**，局部Bundle Adjustment的**优化线程**（Co-visibility Graph，俗称小图 ），以及全局Pose Graph的**回环检测与优化线程**（Essential Graph俗称大图 ）。

5.ORB-SLAM围绕**特征点**进行了不少的优化。例如，在OpenCV的特征提取基础上保证了特征点的**均匀分布**，在优化位姿时使用了一种**循环优化4遍**以得到更多正确匹配的方法，比PTAM更为宽松的关键帧选取策略，等等。

当然，ORB-SLAM也存在一些不足之处。首先，由于整个SLAM系统都采用特征点进行计算，我们必须对每幅图像都计算一遍ORB特征，非常**耗时**。ORB-SLAM的三线程结构也给CPU带来了较重的负担，使得它只有在当前PC架构的CPU上才能实时运算，移植到嵌入式设备上则有一定困难。其次，ORB-SLAM的建图为**稀疏特征点**，目前还没有开放存储和读取地图后重新定位的功能（虽然从实现上来讲并不困难）。根据我们在建图部分的分析，稀疏特征点地图只能满足我们对定位的需求，而无法提供导航、避障、交互等诸多功能。然而，如果我们仅用ORB-SLAM处理定位问题，似乎又显得有些过于重量级了。

### 14.1.4　LSD-SLAM

LSD-SLAM（Large Scale Direct monocular SLAM）是J.Engle等人于2014年提出的。类比于ORB-SLAM之于特征点，LSD-SLAM则标志着**单目直接法**在SLAM中的成功应用。LSD-SLAM的核心贡献是将直接法应用到了半稠密的单目SLAM中。它不仅不需要计算特征点，还能构建半稠密的地图——这里半稠密的意思主要是指估计梯度明显的像素位置。它的主要优点如下：

1.LSD-SLAM的直接法是针对像素进行的。

2.LSD-SLAM在CPU上实现了半稠密场景的重建，这在之前的方案中是很少见到的。

3.LSD-SLAM的半稠密追踪使用了一些精妙的手段来保证追踪的实时性与稳定性。例如，LSD-SLAM既不是利用单个像素，也不是利用图像块，而是在极线上等距离取5个点，度量其SSD；在深度估计时，LSD-SLAM首先用随机数初始化深度，在估计完后又把深度均值归一化，以调整尺度；在度量深度不确定性时，不仅考虑三角化的几何关系，而且考虑了极线与深度的夹角，归纳成一个光度不确定性项；关键帧之间的约束使用了相似变换群及与之对应的李代数$\zeta\in sim(3)$显式地表达出尺度，在后端优化中可以将不同尺度的场景考虑进来，减小了尺度飘移现象。

由于LSD-SLAM使用了直接法进行跟踪，所以它既有直接法的优点（对特征缺失区域不敏感），也继承了直接法的缺点。例如，LSD-SLAM对相机内参和曝光非常敏感，并且在相机快速运动时容易丢失。另外，在回环检测部分，由于目前并没有基于直接法实现的回环检测方式，因此LSD-SLAM必须依赖于特征点方法进行回环检测，尚未完全摆脱特征点的计算。

### 14.1.5　SVO

SVO是Semi-direct Visual Odoemtry的缩写，它是由Forster等人于2014年提出的一种**基于稀疏直接法**的**视觉里程计**。

**半直接**在原文中的意思是指特征点与直接法的混合使用：SVO跟踪了一些关键点（角点，没有描述子），然后像直接法那样，根据这些关键点周围的信息估计相机运动及其位置。在实现中，SVO使用了关键点周围的4×4的小块进行块匹配，估计相机自身的运动。

相比于其他方案，SVO的最大优势是**速度极快**。由于使用稀疏的直接法，即使在低端计算平台上也能达到实时性，而在PC平台上则可以达到每秒100多帧。在后续的SVO 2.0中，速度达到每秒400帧。这使得SVO非常适用于计算平台受限的场合，例如无人机、手持AR/VR设备的定位。无人机也是作者开发SVO的目标应用平台。

SVO的另一创新之处是提出了**深度滤波器**的概念，并推导了基于均匀-高斯混合分布的深度滤波器。SVO将这种滤波器用于关键点的位置估计，并使用了**逆深度**作为参数化形式，使之能够更好地计算特征点位置。

开源版的SVO代码清晰易读，十分适合读者作为第一个SLAM实例进行分析。不过，开源版SVO也存在一些问题：

1.由于目标应用平台为无人机的俯视相机，其视野内的物体主要是地面，而且相机的运动主要为水平和上下的移动，SVO的许多细节是围绕这个应用设计的，这使得它在平视相机中表现不佳。

2.SVO为了速度和轻量化，舍弃了后端优化和回环检测部分，也基本没有建图功能。这意味着SVO的位姿估计必然存在累积误差，而且丢失后不太容易进行重定位（因为没有描述子用来回环检测）。所以，我们称它为一个VO，而不是称它为完整的SLAM。

### 14.1.6　RTAB-MAP

RTAB-MAP（Real Time Appearance-Based Mapping）是**RGB-D** SLAM中比较经典的一个方案。它实现了RGB-D SLAM中所有应该有的东西：基于特征的视觉里程计、基于词袋的回环检测、后端的位姿图优化，以及点云和三角网格地图。因此，RTABMAP给出了一套完整的（但有些庞大的）RGB-D SLAM方案。

## 14.2　未来的SLAM话题

大体上讲，SLAM将来的发展趋势有两大类：一是朝轻量级、小型化方向发展，让SLAM能够在嵌入式或手机等小型设备上良好运行，然后考虑以它为底层功能的应用。另一方面则是利用高性能计算设备，实现精密的三维重建、场景理解等功能。

### 14.2.1　视觉+惯性导航SLAM

目前VIO的框架已经定型为两大类：**松耦合**（Loosely Coupled）和**紧耦合**（Tightly Coupled）。松耦合是指IMU和相机分别进行自身的运动估计，然后对其位姿估计结果进行融合。紧耦合是指把IMU的状态与相机的状态合并在一起，共同构建运动方程和观测方程，然后进行状态估计。

值得一提的是，尽管在纯视觉SLAM中优化方法已经占了主流，但在VIO中，由于IMU的数据**频率**非常高，对状态进行优化需要的计算量就更大，因此目前仍处于**滤波与优化并存**的阶段。

VIO为将来SLAM的小型化与低成本化提供了一个非常有效的方向。而且结合稀疏直接法，我们有望在低端硬件上取得良好的SLAM或VO效果，是非常有前景的。

### 14.2.2　语义SLAM

我们正看到，逐渐开始有学者将神经网络方法引入到SLAM中的物体识别和分割，甚至SLAM本身的位姿估计与回环检测中。虽然这些方法目前还没有成为主流，但将SLAM与深度学习结合来处理图像，亦是一个很有前景的研究方向。