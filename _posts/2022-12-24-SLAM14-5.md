---
layout: post
title:  "第5讲 相机与图像"
subtitle: "高翔《SLAM十四讲》"
date:   2022-12-24 00:00:00 +0800
author:     "ZhouSh"
header-img: "img/in_post/SLAM14/head.png"
header-mask: 0.4
tags:
    - SLAM十四讲
---
# 第5讲　相机与图像

## 5.1 相机模型

### 5.1.1 针孔相机模型

<img src="/img/in_post/SLAM14/5/1.png" width="100%">
设O-x-y-z为相机坐标系，习惯上我们让z轴指向相机前方，x向右，y向下。O为摄像机的光心，也是针孔模型中的针孔。现实世界的空间点P，经过小孔O投影之后，落在物理成像平面O′-x′-y′上，成像点为P′。设P的坐标为$[X,Y,Z]^T$ ，P′为$[X′,Y′,Z′]^T$ ，并且设物理成像平面到小孔的距离为f（焦距）。根据三角形相似关系，有（1）。其中负号表示成的像是倒立的。为了简化模型，我们可以把成像平面对称到相机前方，把公式中的负号去掉，整理得（2）。

$
\frac Zf=-\frac X{X'}=-\frac Y{Y'}
\tag{1}
$

$
X'=f\frac XZ,\ \ Y'=f\frac YZ
\tag{2}
$

在相机中，我们最终获得的是一个个的像素，这需要在成像平面上对像进行采样和量化。假设在物理成像平面上固定着一个像素平面o-u-v 。我们在像素平面得到了P′的像素坐标$[u,v]^T$。

**像素坐标系**通常的定义方式是：原点o′位于图像的左上角，u轴向右与x轴平行，v轴向下与y轴平行。像素坐标系与成像平面之间，相差了一个缩放和一个原点的平移。我们设像素坐标在u轴上缩放了$\alpha$倍，在v上缩放了$\beta$倍。同时，原点平移了$[cx ,cy]^T$。那么，P′的坐标与像素坐标$[u,v ]^T$的关系为（3）。结合上式，得（4）。其中，f的单位为**米**，$\alpha,\beta$的单位为**像素/米**，所以fx，fy的单位为**像素**。

$
u=\alpha X'+c_x,\ \ v=\beta Y'+c_y
\tag{3}
$

$
u=f_x\frac XZ+c_x,\ \ v=f_y\frac YZ+c_y
\tag{4}
$

写成矩阵形式，并整理得下式，我们把中间的量组成的矩阵称为相机的**内参数矩阵**（Camera Intrinsics）。
<img src="/img/in_post/SLAM14/5/2.png" width="40%">

前面使用的是P在**相机坐标系**下的坐标。由于相机在运动，所以P的相机坐标应该是它的**世界坐标**（记为Pw），即根据相机的当前位姿变换到相机坐标系下的结果。相机的位姿由它的旋转矩阵R和平移向量t来描述。那么有下式，其中，**相机的位姿R,t**又称为相机的**外参数**（Camera Extrinsics）。相比于不变的内参，外参会随着相机运动发生改变，同时也是SLAM中待估计的目标，代表着机器人的轨迹。
<img src="/img/in_post/SLAM14/5/3.png" width="50%">

### 5.1.2 畸变

由透镜形状引起的畸变称为**径向畸变**，分为**桶形畸变**和**枕形畸变**。

在相机的组装过程中由于不能使透镜和成像面严格**平行**会引入**切向畸变**。

### 5.1.3　双目相机模型
<img src="/img/in_post/SLAM14/5/4.png" width="100%">
**双目相机***的原理是：通过同步采集左右相机的图像，计算图像间**视差**，来估计每一个像素的深度。双目之间的距离称为**基线**（Baseline，记作b），考虑一个空间点P ，它在左眼相机和右眼相机各成一像，记作$P_L,P_R$。理想情况下，由于左右相机只在x轴上有位移，因此P的像也只在x轴（对应图像的u轴）上有差异。记它的左侧坐标为$u_L$，右侧坐标为$u_R$。那么，其几何关系如上图右侧所示。根据$\Delta PP_LP_R$和$\Delta PO_LO_R$的相似关系，有（5），整理得（6）。

$
\frac{z-f}z=\frac{b-u_L+u_R}b
\tag{5}
$

$
z=\frac{fb}d,\ \ d=u_L-u_R
\tag{6}
$

这里，d为左右图的横坐标之差，称为**视差**（Disparity）。根据视差，我们可以估计一个像素与相机之间的距离。视差与距离成反比：视差越大，距离越近。虽然由视差计算深度的公式很简洁，但视差d 本身的计算却比较困难。

### 5.1.4　RGB-D相机模型

目前的RGB-D相机按原理可分为两大类：

1.通过**红外结构光**测量像素距离。相机根据返回的**结构光图案**，计算物体与自身之间的距离。

2.通过**飞行时间法**测量像素距离。相机向目标发射脉冲光，然后根据发送到返回之间的光束**飞行时间**，确定物体与自身之间的距离。

## 5.2　图像
<img src="/img/in_post/SLAM14/5/5.png" width="100%">
我们平时说的图像的宽度或列数，对应着X轴；而图像的高度或行数，则对应着它的Y轴。根据这种定义方式，如果我们讨论一个位于x,y处的像素，那么它在程序中的访问方式应该是`unsigned char pixel = image[y][x];`